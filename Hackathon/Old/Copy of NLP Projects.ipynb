{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7819,"status":"ok","timestamp":1690180158472,"user":{"displayName":"HummingBird's Tech","userId":"15801504552720898939"},"user_tz":-330},"id":"z2Qio89alg_1","outputId":"53aba56f-7920-47d4-efc9-4369e601589f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.1)\n","Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.22.4)\n","Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.10.1)\n","Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.3.0)\n"]}],"source":["pip install gensim"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fkgQL_3TbYao"},"outputs":[],"source":["\n","# Simple Text Summarization in Python\n","import gensim\n","# import the gensim module and summarize function\n","from gensim.summarization.summarizer import summarize\n","\n","# Paragraph\n","paragraph = \"Natural language processing (NLP) is the ability of a computer program to understand human language as it is spoken. NLP is a component of artificial intelligence (AI). The development of NLP applications is challenging because computers traditionally require humans to 'speak' to them in a programming language that is precise, unambiguous and highly structured, or through a limited number of clearly enunciated voice commands. Human speech, however, is not always precise -- it is often ambiguous and the linguistic structure can depend on many complex variables, including slang, regional dialects and social context.\"\n","\n","# Get the Summary of the text based on percentage (0.5% of the original content).\n","summ_per = summarize(paragraph, ratio = 0.7)\n","print(\"Percent summary:\")\n","print(summ_per)\n","\n","# Get the summary of the text based on number of words (50 words)\n","summ_words = summarize(paragraph, word_count = 30)\n","print(\"\\n\")\n","print(\"Word count summary:\")\n","print(summ_words)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DpaVOzyNbZq2"},"outputs":[],"source":["from gensim.models import Word2Vec\n","from nltk.tokenize import word_tokenize  # You may need to install NLTK\n","import nltk\n","nltk.download('punkt')\n","# Sample corpus (list of sentences)\n","corpus = [\n","    \"This is a sample sentence.\",\n","    \"Word embeddings are fascinating.\",\n","    \"Machine learning is fun.\",\n","]\n","\n","# Tokenize the corpus\n","tokenized_corpus = [word_tokenize(sentence.lower()) for sentence in corpus]\n","\n","# Train the Word2Vec model\n","model = Word2Vec(sentences=tokenized_corpus, vector_size=100, window=5, min_count=1, sg=0)\n","\n","# Input two sentences\n","sentence1 = \"This is a sample text.\"\n","sentence2 = \"Machine learning is interesting.\"\n","\n","# Tokenize and preprocess the input sentences\n","tokenized_sentence1 = word_tokenize(sentence1.lower())\n","tokenized_sentence2 = word_tokenize(sentence2.lower())\n","\n","# Calculate the similarity between the two sentences\n","similarity_score = model.wv.wmdistance(tokenized_sentence1, tokenized_sentence2)\n","\n","# Print the similarity score\n","print(f\"Similarity between '{sentence1}' and '{sentence2}': {similarity_score:.3f}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dhl4vdCNcON7"},"outputs":[],"source":["# Python code to measure similarity between two sentences using similarity.\n","import spacy\n","nlp = spacy.load(\"en_core_web_sm\")\n","\n","# Sentences\n","s1 = nlp(\"The weather is rainy.\")\n","s2 = nlp(\"It is going to rain outside.\")\n","\n","# Calculate the similarity\n","print(\"The similarity is:\",s1.similarity(s2))"]},{"cell_type":"markdown","metadata":{"id":"uS42e1qpj4GV"},"source":["### Word Correction"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WQ_veHFqj9fM"},"outputs":[],"source":["import nltk\n","nltk.download('punkt')\n","\n","from textblob import TextBlob\n","\n","def correct_text_with_textblob(text):\n","    blob = TextBlob(text)\n","    corrected_text = [word.correct() for word in blob.words]\n","    return ' '.join(corrected_text)\n","\n","\n","if __name__ == \"__main__\":\n","    input_text = input(\"Enter a sentence with spelling errors: \")\n","    corrected_text = correct_text_with_textblob(input_text)\n","    print(\"Corrected Text:\", corrected_text)\n"]},{"cell_type":"markdown","metadata":{"id":"hp-JOYgwgdu_"},"source":["### Sentiment Analysis"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1056,"status":"ok","timestamp":1667612755335,"user":{"displayName":"HummingBird's Tech","userId":"15801504552720898939"},"user_tz":-330},"id":"g0QsXaricjPS","outputId":"29dc0b0f-7b3c-447e-b682-86e6d8def4e1"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package twitter_samples to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/twitter_samples.zip.\n"]},{"data":{"text/plain":["True"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["\n","# Installing NLTK and Downloading the Data\n","\n","\n","import nltk\n","nltk.download('twitter_samples')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uzuLJ0_ndj1a"},"outputs":[],"source":["# Tokenizing the Data\n","\n","from nltk.corpus import twitter_samples"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CKCnZ9SNd3RV"},"outputs":[],"source":["positive_tweets = twitter_samples.strings('positive_tweets.json')\n","negative_tweets = twitter_samples.strings('negative_tweets.json')\n","text = twitter_samples.strings('tweets.20150430-223406.json')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":691,"status":"ok","timestamp":1667612806740,"user":{"displayName":"HummingBird's Tech","userId":"15801504552720898939"},"user_tz":-330},"id":"O_6Boszmd8qG","outputId":"f0eec37f-73e3-4b55-c748-bc2b44a48853"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"data":{"text/plain":["True"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["# The punkt module is a pre-trained model that helps you tokenize words and sentences.\n","\n","nltk.download('punkt')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1242,"status":"ok","timestamp":1667612824775,"user":{"displayName":"HummingBird's Tech","userId":"15801504552720898939"},"user_tz":-330},"id":"kg8f4PYDeAdr","outputId":"1c478633-9c56-4325-ec7f-293d2dac8d40"},"outputs":[{"name":"stdout","output_type":"stream","text":["#FollowFriday\n"]}],"source":["tweet_tokens = twitter_samples.tokenized('positive_tweets.json')[0]\n","\n","print(tweet_tokens[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":505,"status":"ok","timestamp":1667612883953,"user":{"displayName":"HummingBird's Tech","userId":"15801504552720898939"},"user_tz":-330},"id":"yNhs-FZ1eExa","outputId":"668630ae-5e3e-4b95-be30-ec8382eb8eeb"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"]},{"data":{"text/plain":["True"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["# wordnet is a lexical database for the English language that helps the script determine the base word.\n","# You need the averaged_perceptron_tagger resource to determine the context of a word in a sentence.\n","\n","nltk.download('wordnet')\n","nltk.download('averaged_perceptron_tagger')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1859,"status":"ok","timestamp":1667612901812,"user":{"displayName":"HummingBird's Tech","userId":"15801504552720898939"},"user_tz":-330},"id":"xlVb4YMjeTc5","outputId":"5ed3aedf-c034-4864-b9d0-0535904e18f5"},"outputs":[{"name":"stdout","output_type":"stream","text":["[('#FollowFriday', 'JJ'), ('@France_Inte', 'NNP'), ('@PKuchly57', 'NNP'), ('@Milipol_Paris', 'NNP'), ('for', 'IN'), ('being', 'VBG'), ('top', 'JJ'), ('engaged', 'VBN'), ('members', 'NNS'), ('in', 'IN'), ('my', 'PRP$'), ('community', 'NN'), ('this', 'DT'), ('week', 'NN'), (':)', 'NN')]\n"]}],"source":["tweet_tokens = twitter_samples.tokenized('positive_tweets.json')\n","print(pos_tag(tweet_tokens[0]))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2632,"status":"ok","timestamp":1667612991387,"user":{"displayName":"HummingBird's Tech","userId":"15801504552720898939"},"user_tz":-330},"id":"Pgnh9IXLeXYH","outputId":"ceac8a42-34a9-457d-8cd8-472eec4fba2e"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"]},{"name":"stdout","output_type":"stream","text":["['#FollowFriday', '@France_Inte', '@PKuchly57', '@Milipol_Paris', 'for', 'be', 'top', 'engage', 'member', 'in', 'my', 'community', 'this', 'week', ':)']\n"]}],"source":["...\n","\n","from nltk.tag import pos_tag\n","from nltk.stem.wordnet import WordNetLemmatizer\n","nltk.download('omw-1.4')\n","\n","def lemmatize_sentence(tokens):\n","    lemmatizer = WordNetLemmatizer()\n","    lemmatized_sentence = []\n","    for word, tag in pos_tag(tokens):\n","        if tag.startswith('NN'):\n","            pos = 'n'\n","        elif tag.startswith('VB'):\n","            pos = 'v'\n","        else:\n","            pos = 'a'\n","        lemmatized_sentence.append(lemmatizer.lemmatize(word, pos))\n","    return lemmatized_sentence\n","\n","print(lemmatize_sentence(tweet_tokens[0]))\n","\n","# https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ttbDs2qYed7U"},"outputs":[],"source":["# Removing Noise from the Data\n","\n","import re, string\n","\n","def remove_noise(tweet_tokens, stop_words = ()):\n","\n","    cleaned_tokens = []\n","\n","    for token, tag in pos_tag(tweet_tokens):\n","        token = re.sub('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+#]|[!*\\(\\),]|'\\\n","                       '(?:%[0-9a-fA-F][0-9a-fA-F]))+','', token)\n","        token = re.sub(\"(@[A-Za-z0-9_]+)\",\"\", token)\n","\n","        if tag.startswith(\"NN\"):\n","            pos = 'n'\n","        elif tag.startswith('VB'):\n","            pos = 'v'\n","        else:\n","            pos = 'a'\n","\n","        lemmatizer = WordNetLemmatizer()\n","        token = lemmatizer.lemmatize(token, pos)\n","\n","        if len(token) > 0 and token not in string.punctuation and token.lower() not in stop_words:\n","            cleaned_tokens.append(token.lower())\n","    return cleaned_tokens"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1667613040348,"user":{"displayName":"HummingBird's Tech","userId":"15801504552720898939"},"user_tz":-330},"id":"KiXWeObQeyZF","outputId":"85fbae5f-8cd4-4ef1-ffb7-324c5bf6ebc3"},"outputs":[{"name":"stdout","output_type":"stream","text":["['#followfriday', 'top', 'engage', 'member', 'community', 'week', ':)']\n"]},{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]}],"source":["...\n","nltk.download('stopwords')\n","from nltk.corpus import stopwords\n","\n","stop_words = stopwords.words('english')\n","\n","print(remove_noise(tweet_tokens[0], stop_words))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TBF_TVZhe0y_"},"outputs":[],"source":["stop_words = stopwords.words('english')\n","\n","#print(remove_noise(tweet_tokens[0], stop_words))\n","\n","positive_tweet_tokens = twitter_samples.tokenized('positive_tweets.json')\n","negative_tweet_tokens = twitter_samples.tokenized('negative_tweets.json')\n","\n","positive_cleaned_tokens_list = []\n","negative_cleaned_tokens_list = []\n","\n","for tokens in positive_tweet_tokens:\n","    positive_cleaned_tokens_list.append(remove_noise(tokens, stop_words))\n","\n","for tokens in negative_tweet_tokens:\n","    negative_cleaned_tokens_list.append(remove_noise(tokens, stop_words))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1667613103125,"user":{"displayName":"HummingBird's Tech","userId":"15801504552720898939"},"user_tz":-330},"id":"cXEPMdSgfEPY","outputId":"e1a087c4-a943-4187-f3b0-72c73e23e97a"},"outputs":[{"name":"stdout","output_type":"stream","text":["['Dang', 'that', 'is', 'some', 'rad', '@AbzuGame', '#fanart', '!', ':D', 'https://t.co/bI8k8tb9ht']\n","['dang', 'rad', '#fanart', ':d']\n"]}],"source":["...\n","print(positive_tweet_tokens[500])\n","print(positive_cleaned_tokens_list[500])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pZayNFqOfI-Y"},"outputs":[],"source":["...\n","\n","def get_all_words(cleaned_tokens_list):\n","    for tokens in cleaned_tokens_list:\n","        for token in tokens:\n","            yield token\n","\n","all_pos_words = get_all_words(positive_cleaned_tokens_list)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1667613160581,"user":{"displayName":"HummingBird's Tech","userId":"15801504552720898939"},"user_tz":-330},"id":"GAyoH_SwfTUo","outputId":"065f93c9-30c6-4af2-988b-a11494f190a2"},"outputs":[{"name":"stdout","output_type":"stream","text":["[(':)', 3691), (':-)', 701), (':d', 658), ('thanks', 388), ('follow', 357), ('love', 333), ('...', 290), ('good', 283), ('get', 263), ('thank', 253)]\n"]}],"source":["from nltk import FreqDist\n","\n","freq_dist_pos = FreqDist(all_pos_words)\n","print(freq_dist_pos.most_common(10))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q3htqSZXfXEt"},"outputs":[],"source":["...\n","def get_tweets_for_model(cleaned_tokens_list):\n","    for tweet_tokens in cleaned_tokens_list:\n","        yield dict([token, True] for token in tweet_tokens)\n","\n","positive_tokens_for_model = get_tweets_for_model(positive_cleaned_tokens_list)\n","negative_tokens_for_model = get_tweets_for_model(negative_cleaned_tokens_list)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3nsiiFl5fZ2X"},"outputs":[],"source":["...\n","import random\n","\n","positive_dataset = [(tweet_dict, \"Positive\")\n","                     for tweet_dict in positive_tokens_for_model]\n","\n","negative_dataset = [(tweet_dict, \"Negative\")\n","                     for tweet_dict in negative_tokens_for_model]\n","\n","dataset = positive_dataset + negative_dataset\n","\n","random.shuffle(dataset)\n","\n","train_data = dataset[:7000]\n","test_data = dataset[7000:]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1335,"status":"ok","timestamp":1667613188831,"user":{"displayName":"HummingBird's Tech","userId":"15801504552720898939"},"user_tz":-330},"id":"z1N1FJuHfbum","outputId":"2cb79f31-94a8-41fc-8426-9ede1107ccde"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy is: 0.9956666666666667\n","Most Informative Features\n","                      :( = True           Negati : Positi =   2029.1 : 1.0\n","                      :) = True           Positi : Negati =    996.6 : 1.0\n","                     sad = True           Negati : Positi =     33.0 : 1.0\n","                follower = True           Positi : Negati =     29.7 : 1.0\n","                     bam = True           Positi : Negati =     22.2 : 1.0\n","                     x15 = True           Negati : Positi =     15.9 : 1.0\n","                    glad = True           Positi : Negati =     13.3 : 1.0\n","                    blog = True           Positi : Negati =     12.6 : 1.0\n","               community = True           Positi : Negati =     12.6 : 1.0\n","                   didnt = True           Negati : Positi =     11.4 : 1.0\n","None\n"]}],"source":["...\n","from nltk import classify\n","from nltk import NaiveBayesClassifier\n","classifier = NaiveBayesClassifier.train(train_data)\n","\n","print(\"Accuracy is:\", classify.accuracy(classifier, test_data))\n","\n","print(classifier.show_most_informative_features(10))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1667613256313,"user":{"displayName":"HummingBird's Tech","userId":"15801504552720898939"},"user_tz":-330},"id":"B7gsuR8LfdnW","outputId":"d208d2a2-186e-4142-a5fc-98bd5174b89e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Negative\n"]}],"source":["...\n","from nltk.tokenize import word_tokenize\n","\n","custom_tweet = \"The Foood Was Good\"\n","\n","custom_tokens = remove_noise(word_tokenize(custom_tweet))\n","\n","print(classifier.classify(dict([token, True] for token in custom_tokens)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GtQi60Hxfhvz"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"aPkQ9_rOzSAV"},"source":["Simple Rule Bases ChatBot"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XkWhUOVEzV3g"},"outputs":[],"source":["from nltk.chat.util import Chat, reflections"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lCarj-01zZNn"},"outputs":[],"source":["#Pairs is a list of patterns and responses.\n","pairs = [\n","    [\n","        r\"(.*)my name is (.*)\",\n","        [\"Hello %2, How are you today ?\",]\n","    ],\n","    [\n","        r\"(.*)help(.*) \",\n","        [\"I can help you \",]\n","    ],\n","     [\n","        r\"(.*) your name ?\",\n","        [\"My name is Ahya, but you can just call me robot and I'm a chatbot .\",]\n","    ],\n","    [\n","        r\"how are you (.*) ?\",\n","        [\"I'm doing very well\", \"i am great !\"]\n","    ],\n","    [\n","        r\"sorry (.*)\",\n","        [\"Its alright\",\"Its OK, never mind that\",]\n","    ],\n","    [\n","        r\"i'm (.*) (good|well|okay|ok)\",\n","        [\"Nice to hear that\",\"Alright, great !\",]\n","    ],\n","    [\n","        r\"(hi|hey|hello|hola|holla)(.*)\",\n","        [\"Hello\", \"Hey there\",]\n","    ],\n","    [\n","        r\"what (.*) want ?\",\n","        [\"Make me an offer I can't refuse\",]\n","\n","    ],\n","    [\n","        r\"(.*)created(.*)\",\n","        [\"Created By NLTK created me using Python's NLTK library \",\"top secret ;)\",]\n","    ],\n","    [\n","        r\"(.*) (location|city) ?\",\n","        ['Banglore, India',]\n","    ],\n","    [\n","        r\"(.*)raining in (.*)\",\n","        [\"No rain in the past 4 days here in %2\",\"In %2 there is a 50% chance of rain\",]\n","    ],\n","    [\n","        r\"how (.*) health (.*)\",\n","        [\"Health is very important, but I am a computer, so I don't need to worry about my health \",]\n","    ],\n","    [\n","        r\"(.*)(sports|game|sport)(.*)\",\n","        [\"I'm a very big fan of Cricket\",]\n","    ],\n","    [\n","        r\"who (.*) (Cricketer|Batsman)?\",\n","        [\"Virat Kohli\"]\n","    ],\n","    [\n","        r\"quit\",\n","        [\"Bye for now. See you soon :) \",\"It was nice talking to you.\"]\n","    ],\n","    [\n","        r\"(.*)\",\n","        ['That is nice to hear']\n","    ],\n","]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1667786467219,"user":{"displayName":"HummingBird's Tech","userId":"15801504552720898939"},"user_tz":-330},"id":"vyZMvvv70aIQ","outputId":"a443b452-ac08-41dd-e037-a179dd524dd2"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'i am': 'you are', 'i was': 'you were', 'i': 'you', \"i'm\": 'you are', \"i'd\": 'you would', \"i've\": 'you have', \"i'll\": 'you will', 'my': 'your', 'you are': 'I am', 'you were': 'I was', \"you've\": 'I have', \"you'll\": 'I will', 'your': 'my', 'yours': 'mine', 'you': 'me', 'me': 'you'}\n"]}],"source":["print(reflections)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e_u0HYCY0eFn"},"outputs":[],"source":["my_dummy_reflections= {\n","    \"go\"     : \"gone\",\n","    \"hello\"    : \"hey there\"\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":734,"status":"ok","timestamp":1667786519349,"user":{"displayName":"HummingBird's Tech","userId":"15801504552720898939"},"user_tz":-330},"id":"8TsWklly0gxI","outputId":"ec490d44-8520-4566-a460-8d05b28b3f03"},"outputs":[{"name":"stdout","output_type":"stream","text":["Hi, I'm Ahya and I like to chat\n","Please type lowercase English language to start a conversation. Type quit to leave \n"]}],"source":["#default message at the start of chat\n","print(\"Hi, I'm Ahya and I like to chat\\nPlease type lowercase English language to start a conversation. Type quit to leave \")\n","#Create Chat Bot\n","chat = Chat(pairs, reflections)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":34628,"status":"ok","timestamp":1667786567590,"user":{"displayName":"HummingBird's Tech","userId":"15801504552720898939"},"user_tz":-330},"id":"zVWajzqU0quP","outputId":"3a979607-c6e3-4f7e-e24f-9ae37549344c"},"outputs":[{"name":"stdout","output_type":"stream","text":[">Hello\n","Hello\n",">How Are you\n","That is nice to hear\n",">Who Are you\n","Virat Kohli\n",">Are You Sure\n","That is nice to hear\n",">quit\n","It was nice talking to you.\n"]}],"source":["chat.converse()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DOU6EjN60uKU"},"outputs":[],"source":["import pandas as pd\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","dataset = [\n","    \"I enjoy reading about Machine Learning and Machine Learning is my PhD subject\",\n","    \"I would enjoy a walk in the park\",\n","    \"I was reading in the library\"\n","]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1668241832178,"user":{"displayName":"HummingBird's Tech","userId":"15801504552720898939"},"user_tz":-330},"id":"vyVJICqY9Qyi","outputId":"b3740831-d394-4dfa-e625-3c6f942bddaa"},"outputs":[{"name":"stdout","output_type":"stream","text":["            TF-IDF\n","machine   0.513720\n","learning  0.513720\n","about     0.256860\n","subject   0.256860\n","phd       0.256860\n","and       0.256860\n","my        0.256860\n","is        0.256860\n","reading   0.195349\n","enjoy     0.195349\n","library   0.000000\n","park      0.000000\n","in        0.000000\n","the       0.000000\n","walk      0.000000\n","was       0.000000\n","would     0.000000\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n","  warnings.warn(msg, category=FutureWarning)\n"]}],"source":["tfIdfVectorizer = TfidfVectorizer(use_idf=True)\n","tfIdf = tfIdfVectorizer.fit_transform(dataset)\n","df = pd.DataFrame(tfIdf[0].T.todense(), index=tfIdfVectorizer.get_feature_names(), columns=[\"TF-IDF\"])\n","df = df.sort_values('TF-IDF', ascending=False)\n","print (df.head(25))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N7r3TxZP9Xrz"},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import SimpleRNN, LSTM, Dense\n","\n","# Generate some sequential data (time series)\n","np.random.seed(42)\n","data = np.random.random((100, 10, 1))\n","\n","# Generate the target labels (e.g., binary classification)\n","labels = np.random.randint(2, size=(100, 1))\n","\n","# Split the data into training and test sets\n","train_data = data[:80]\n","train_labels = labels[:80]\n","test_data = data[80:]\n","test_labels = labels[80:]\n","\n","# Build the RNN model\n","rnn_model = Sequential()\n","rnn_model.add(SimpleRNN(32, input_shape=(10, 1)))\n","rnn_model.add(Dense(1, activation='sigmoid'))\n","\n","# Compile and train the RNN model\n","rnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","rnn_model.fit(train_data, train_labels, epochs=5, batch_size=16, validation_split=0.2)\n","\n","# Evaluate the RNN model on the test set\n","rnn_loss, rnn_accuracy = rnn_model.evaluate(test_data, test_labels)\n","print(\"RNN Test accuracy:\", rnn_accuracy)\n","\n","# Build the LSTM model\n","lstm_model = Sequential()\n","lstm_model.add(LSTM(32, input_shape=(10, 1)))\n","lstm_model.add(Dense(1, activation='sigmoid'))\n","\n","# Compile and train the LSTM model\n","lstm_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","lstm_model.fit(train_data, train_labels, epochs=5, batch_size=16, validation_split=0.2)\n","\n","# Evaluate the LSTM model on the test set\n","lstm_loss, lstm_accuracy = lstm_model.evaluate(test_data, test_labels)\n","print(\"LSTM Test accuracy:\", lstm_accuracy)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":338891,"status":"ok","timestamp":1700915230750,"user":{"displayName":"HummingBird's Tech","userId":"15801504552720898939"},"user_tz":-330},"id":"epwbJTpmPSah","outputId":"b331e275-29ec-477b-be08-a86f390e0be1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n","17464789/17464789 [==============================] - 0s 0us/step\n","Epoch 1/5\n","313/313 [==============================] - 73s 205ms/step - loss: 0.6235 - accuracy: 0.6220 - val_loss: 0.4515 - val_accuracy: 0.7976\n","Epoch 2/5\n","313/313 [==============================] - 36s 117ms/step - loss: 0.3606 - accuracy: 0.8439 - val_loss: 0.4015 - val_accuracy: 0.8226\n","Epoch 3/5\n","313/313 [==============================] - 38s 120ms/step - loss: 0.2186 - accuracy: 0.9187 - val_loss: 0.4441 - val_accuracy: 0.8078\n","Epoch 4/5\n","313/313 [==============================] - 36s 114ms/step - loss: 0.1008 - accuracy: 0.9675 - val_loss: 0.5383 - val_accuracy: 0.8108\n","Epoch 5/5\n","313/313 [==============================] - 33s 104ms/step - loss: 0.0532 - accuracy: 0.9850 - val_loss: 0.6390 - val_accuracy: 0.8016\n","782/782 [==============================] - 9s 11ms/step - loss: 0.6285 - accuracy: 0.8014\n","SimpleRNN Test accuracy: 0.8014400005340576\n","Epoch 1/5\n","313/313 [==============================] - 22s 60ms/step - loss: 0.4543 - accuracy: 0.7818 - val_loss: 0.3448 - val_accuracy: 0.8450\n","Epoch 2/5\n","313/313 [==============================] - 7s 24ms/step - loss: 0.2644 - accuracy: 0.8953 - val_loss: 0.3607 - val_accuracy: 0.8508\n","Epoch 3/5\n","313/313 [==============================] - 4s 14ms/step - loss: 0.1974 - accuracy: 0.9269 - val_loss: 0.4127 - val_accuracy: 0.8396\n","Epoch 4/5\n","313/313 [==============================] - 4s 14ms/step - loss: 0.1578 - accuracy: 0.9427 - val_loss: 0.4498 - val_accuracy: 0.8344\n","Epoch 5/5\n","313/313 [==============================] - 3s 11ms/step - loss: 0.1200 - accuracy: 0.9586 - val_loss: 0.4632 - val_accuracy: 0.8316\n","782/782 [==============================] - 3s 4ms/step - loss: 0.4713 - accuracy: 0.8298\n","LSTM Test accuracy: 0.8298400044441223\n"]}],"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.datasets import imdb\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import SimpleRNN, LSTM, Dense, Embedding\n","\n","# Load the IMDB movie reviews dataset\n","num_words = 10000  # Only use the most frequent 10,000 words\n","max_len = 100  # Maximum length of each review (pad or truncate to this length)\n","(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=num_words)\n","\n","# Pad sequences to a fixed length\n","x_train = pad_sequences(x_train, maxlen=max_len)\n","x_test = pad_sequences(x_test, maxlen=max_len)\n","\n","# Build the SimpleRNN model\n","rnn_model = Sequential()\n","rnn_model.add(Embedding(input_dim=num_words, output_dim=32, input_length=max_len))\n","rnn_model.add(SimpleRNN(32))\n","rnn_model.add(Dense(1, activation='sigmoid'))\n","\n","# Compile and train the SimpleRNN model\n","rnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","rnn_model.fit(x_train, y_train, epochs=5, batch_size=64, validation_split=0.2)\n","\n","# Evaluate the SimpleRNN model on the test set\n","rnn_loss, rnn_accuracy = rnn_model.evaluate(x_test, y_test)\n","print(\"SimpleRNN Test accuracy:\", rnn_accuracy)\n","\n","# Build the LSTM model\n","lstm_model = Sequential()\n","lstm_model.add(Embedding(input_dim=num_words, output_dim=32, input_length=max_len))\n","lstm_model.add(LSTM(32))\n","lstm_model.add(Dense(1, activation='sigmoid'))\n","\n","# Compile and train the LSTM model\n","lstm_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","lstm_model.fit(x_train, y_train, epochs=5, batch_size=64, validation_split=0.2)\n","\n","# Evaluate the LSTM model on the test set\n","lstm_loss, lstm_accuracy = lstm_model.evaluate(x_test, y_test)\n","print(\"LSTM Test accuracy:\", lstm_accuracy)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12421,"status":"ok","timestamp":1690181220874,"user":{"displayName":"HummingBird's Tech","userId":"15801504552720898939"},"user_tz":-330},"id":"SM0D-moe6aCW","outputId":"56bd83d9-1852-4e8b-aeb6-a2246965490a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","4/4 [==============================] - 2s 7ms/step - loss: 0.6928 - accuracy: 0.7500\n","Epoch 2/10\n","4/4 [==============================] - 0s 6ms/step - loss: 0.6688 - accuracy: 0.7500\n","Epoch 3/10\n","4/4 [==============================] - 0s 6ms/step - loss: 0.6485 - accuracy: 0.7500\n","Epoch 4/10\n","4/4 [==============================] - 0s 6ms/step - loss: 0.6184 - accuracy: 0.7500\n","Epoch 5/10\n","4/4 [==============================] - 0s 6ms/step - loss: 0.5928 - accuracy: 0.7500\n","Epoch 6/10\n","4/4 [==============================] - 0s 6ms/step - loss: 0.5618 - accuracy: 0.7500\n","Epoch 7/10\n","4/4 [==============================] - 0s 6ms/step - loss: 0.5324 - accuracy: 0.7500\n","Epoch 8/10\n","4/4 [==============================] - 0s 6ms/step - loss: 0.4795 - accuracy: 0.7500\n","Epoch 9/10\n","4/4 [==============================] - 0s 6ms/step - loss: 0.4571 - accuracy: 0.7500\n","Epoch 10/10\n","4/4 [==============================] - 0s 6ms/step - loss: 0.4390 - accuracy: 0.7500\n","1/1 [==============================] - 1s 510ms/step - loss: 1.6198 - accuracy: 0.0000e+00\n","Test Loss: 1.619825005531311, Test Accuracy: 0.0\n","Enter your text: I Love Mango\n","1/1 [==============================] - 0s 467ms/step\n","Sentiment: Negative\n"]}],"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import LSTM, Embedding, Dense\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from sklearn.model_selection import train_test_split\n","\n","# Sample data for sentiment analysis\n","texts = [\"I love this product!\", \"This is amazing!\", \"I dislike it.\", \"I'm not a fan.\", \"It's terrible.\"]\n","labels = [1, 1, 0, 0, 0]  # 1 for positive sentiment, 0 for negative sentiment\n","\n","# Tokenize the text and convert to sequences\n","tokenizer = Tokenizer()\n","tokenizer.fit_on_texts(texts)\n","sequences = tokenizer.texts_to_sequences(texts)\n","\n","# Pad sequences to the same length\n","max_len = 10\n","padded_sequences = pad_sequences(sequences, maxlen=max_len)\n","\n","# Convert labels to numpy array\n","y = np.array(labels)\n","\n","# Split data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(padded_sequences, y, test_size=0.2, random_state=42)\n","\n","# LSTM model creation\n","model = Sequential()\n","model.add(Embedding(len(tokenizer.word_index) + 1, 64, input_length=max_len))\n","model.add(LSTM(64))\n","model.add(Dense(1, activation='sigmoid'))\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# Train the model\n","model.fit(X_train, y_train, epochs=10, batch_size=1)\n","\n","# Evaluate the model on test data\n","loss, accuracy = model.evaluate(X_test, y_test)\n","print(f\"Test Loss: {loss}, Test Accuracy: {accuracy}\")\n","\n","# Sentiment classification function\n","def classify_sentiment(text):\n","    # Preprocess the input text\n","    input_sequence = tokenizer.texts_to_sequences([text])\n","    padded_input = pad_sequences(input_sequence, maxlen=max_len)\n","\n","    # Make a prediction\n","    prediction = model.predict(padded_input)[0][0]\n","\n","    # Determine the sentiment class\n","    if prediction >= 0.7:\n","        return \"Positive\"\n","    elif prediction <= 0.3:\n","        return \"Negative\"\n","    else:\n","        return \"Neutral\"\n","\n","# User input for sentiment classification\n","user_input = input(\"Enter your text: \")\n","sentiment = classify_sentiment(user_input)\n","print(f\"Sentiment: {sentiment}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16633,"status":"ok","timestamp":1690181387199,"user":{"displayName":"HummingBird's Tech","userId":"15801504552720898939"},"user_tz":-330},"id":"cT3K2yOXp1Hl","outputId":"059650ce-fa8c-4cfd-e3d2-e05459ad3041"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting transformers\n","  Downloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n","Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n","  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m87.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n","  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m68.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.5.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.16.4 safetensors-0.3.1 tokenizers-0.13.3 transformers-4.31.0\n"]}],"source":["!pip install transformers\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":718,"referenced_widgets":["5a038e1c4ec54db0aaaf3e52a98c3aeb","50c04146cd564b8d87b7adb5a8b6c5b5","7f7d2645fc51437091f1973ffcb8ea73","4c4d40f3c5e248d1b211eecedcd872ed","fedd8f4e19c5497b83e82d9168085bac","c79e4bcae0a84ccbad2e93fe68a6d065","86e4a4ff2ed24c1ebd55a96426803374","5c737cc0b2fa49f3bb6c740237285198","7c8132ed06834bb2a8bb228c153042b7","1124a1dc20644467bfb89d6c1e16db2a","5b1fd71a126140bca9bfb6cadff694f3","76d468216f9c41ad8b4f0416573236dc","57900d8c7e92422bbbdbfade9aa2e956","12bc38728de44a07965f879779530323","5601fa2bf7b94502ae0c41e3e9608b4f","3a7c000be3414b4f82c00db306f60db1","ef313157c8dd4dc7b34b9da8aebb4ead","f3f0be219dc84ebda8f3b581bad481f8","63c4eb22837e4fe0a5d09a6e86b504fb","4cfe845d4629457fb5538abafe8683b5","636e3ddb13f245f3b50fe779285e3b60","beb36773ab6045ceacb291d3aa624037","9baa1971c83344c99d7b0c77149c2aad","3e39c30ecb4f42fa9b547206ae461064","e733318cefa141d69255cf395516062c","5a300bc8e74d4b61b06aabcacfffbef3","e637701765d449c4a0f5d1dd39767e16","b154f814faca40de8da2ae42f0cbcc0c","767ef0d4632641a899a29f60089edfea","5a8e01b3610844faa200f1255a1fdaa5","b30a028edb674ca09875b0eba3578dc6","b8c96f049a564da281fb6db766d2b83f","8cd82deacc9f482cb5b14af93d544428","f26e711a4bce4860bc152298ed7f9e42","328c5b9f1c364ef8810b733158e39536","6804a5b303134aa5a942ae628c0633b0","25e4bf1c328641f0b66040244f0d2947","c322522ace7346c2b5eeed492582d411","7ac4cc69727243b3933d22558a8cb551","0fcaacc473854d5ca4ba8eb3dc5d8592","bd7eda5aa11640b79e0190b156365475","da6eabf6d014466a9896881362783f4b","97da7963163d4fc09631af23f9c1fc1e","a15fecf2e695430d8fbe6bc5e07d27ac","b5d95b3652b24d93a4cc597e45cc9384","153069c35ca440be940f49e9c5c65294","36ef3fa1e69d47eb8fbdc0d9b285dd26","69ca8c5551f14496beb0cd8d7cd0479e","9f5e4df6608f4df08e8784cd47dfe77e","15bfdced7d0141759287b9790726a04c","b5c3dedf6ce948a3a26b7e43769a9bab","9b09e2e4ff7843fdba3957fb1c41af2d","fb0667832da543cd8880c905b0636476","f2a9aaf4d6e9413b944f9163b609932c","ac4487649d83456cbcaf805c41248631"]},"executionInfo":{"elapsed":95724,"status":"ok","timestamp":1690181494785,"user":{"displayName":"HummingBird's Tech","userId":"15801504552720898939"},"user_tz":-330},"id":"AYF3YO-XpWDH","outputId":"fdd0c55e-e6a3-4a58-e77e-1ff45063024e"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5a038e1c4ec54db0aaaf3e52a98c3aeb","version_major":2,"version_minor":0},"text/plain":["Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"76d468216f9c41ad8b4f0416573236dc","version_major":2,"version_minor":0},"text/plain":["Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9baa1971c83344c99d7b0c77149c2aad","version_major":2,"version_minor":0},"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f26e711a4bce4860bc152298ed7f9e42","version_major":2,"version_minor":0},"text/plain":["Downloading model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b5d95b3652b24d93a4cc597e45cc9384","version_major":2,"version_minor":0},"text/plain":["Downloading (…)neration_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Chatbot: Hi! I'm your friendly chatbot. How can I assist you today?\n","You: WHat Is Computer\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["Chatbot: You: WHat Is Computer Gaming?\n","\n","A: Computer gaming is a hobby. It's a hobby that's been around for a long time. It's a hobby that's been around for a long time. It's a hobby that's been around for a long time. It's a hobby that's been around for a long time. It's a hobby that's been around for a long time. It's a hobby that's been around for a long time. It's a hobby\n","You: WHats your name\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["Chatbot: You: WHats your name?\n","\n","A: I'm a little bit of a nerd.\n","\n","Q: What's your favorite movie?\n","\n","A: I'm a little bit of a nerd.\n","\n","Q: What's your favorite movie?\n","\n","A: I'm a little bit of a nerd.\n","\n","Q: What's your favorite movie?\n","\n","A: I'm a little bit of a nerd.\n","\n","Q: What's your favorite movie?\n","\n","You: exit\n","Chatbot: Goodbye! Have a great day!\n"]}],"source":["import torch\n","from transformers import GPT2Tokenizer, GPT2LMHeadModel\n","\n","# Load pre-trained GPT-2 model and tokenizer\n","model_name = \"gpt2\"  # You can also try \"gpt2-medium\", \"gpt2-large\", etc., for larger models\n","tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n","model = GPT2LMHeadModel.from_pretrained(model_name)\n","\n","# Define maximum length for generated responses\n","max_length = 100\n","\n","# Initial welcome message\n","print(\"Chatbot: Hi! I'm your friendly chatbot. How can I assist you today?\")\n","while True:\n","    user_input = input(\"You: \")\n","    if user_input.lower() in ['exit', 'bye', 'quit']:\n","        print(\"Chatbot: Goodbye! Have a great day!\")\n","        break\n","\n","    # Tokenize the input and convert to tensor\n","    input_ids = tokenizer.encode(\"You: \" + user_input, return_tensors='pt')\n","\n","    # Generate a response using the model\n","    with torch.no_grad():\n","        output = model.generate(input_ids, max_length=max_length)\n","\n","    # Decode the generated output and display the chatbot's response\n","    response = tokenizer.decode(output[0], skip_special_tokens=True)\n","    print(\"Chatbot:\", response)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":208033,"status":"ok","timestamp":1690181706373,"user":{"displayName":"HummingBird's Tech","userId":"15801504552720898939"},"user_tz":-330},"id":"GQY9dryTqP8r","outputId":"614b391a-789e-4c58-850e-815d9c77eef6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Chatbot: Hi! I'm your friendly chatbot. How can I assist you today?\n","You: WHat Is Computer\n","Chatbot: You: WHat Is Computer Gaming?\n","\n","A: Computer gaming is a hobby. It's a hobby that's been around for a long time. It's a hobby that's been around for a long time. It's a hobby that's been around for a long time. It's a hobby that's been around for a long time. It's a hobby that's been around for a long time. It's a hobby that's been around for a long time. It's a hobby\n","You: What is Laptop\n","Chatbot: You: What is Laptop?\n","\n","A: Laptop is a computer that is used to run Windows. It is a computer that is used to run Linux. It is a computer that is used to run Mac OS X. It is a computer that is used to run Linux. It is a computer that is used to run Windows. It is a computer that is used to run Mac OS X. It is a computer that is used to run Windows. It is a computer that is used\n","You: Explain The Process of Photosyntehis\n","Chatbot: You: Explain The Process of Photosyntehis\n","\n","You: How Do You Use Photosyntehis?\n","\n","You: How Do You Use Photosyntehis?\n","\n","You: How Do You Use Photosyntehis?\n","\n","You: How Do You Use Photosyntehis?\n","\n","You: How Do You Use Photosyntehis?\n","\n","You: How Do You Use Photosyntehis?\n","\n","You: How Do You Use Photosyntehis\n","You: \n","Chatbot: You:  I'm not sure if you're aware of the fact that I'm a big fan of the \"I'm a big fan of the \"I'm a big fan of the \"I'm a big fan of the \"I'm a big fan of the \"I'm a big fan of the \"I'm a big fan of the \"I'm a big fan of the \"I'm a big fan of the \"I'm a big fan of the \"I'm a big\n","You: exit\n","Chatbot: Goodbye! Have a great day!\n"]}],"source":["import torch\n","from transformers import GPT2Tokenizer, GPT2LMHeadModel\n","\n","# Load pre-trained GPT-2 model and tokenizer\n","model_name = \"gpt2\"  # You can also try \"gpt2-medium\", \"gpt2-large\", etc., for larger models\n","tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n","model = GPT2LMHeadModel.from_pretrained(model_name)\n","\n","# Define maximum length for generated responses\n","max_length = 100\n","\n","# Initial welcome message\n","print(\"Chatbot: Hi! I'm your friendly chatbot. How can I assist you today?\")\n","while True:\n","    user_input = input(\"You: \")\n","    if user_input.lower() in ['exit', 'bye', 'quit']:\n","        print(\"Chatbot: Goodbye! Have a great day!\")\n","        break\n","\n","    # Tokenize the input and convert to tensor\n","    input_ids = tokenizer.encode(\"You: \" + user_input, return_tensors='pt')\n","\n","    # Generate a response using the model\n","    with torch.no_grad():\n","        output = model.generate(input_ids, max_length=max_length, pad_token_id=tokenizer.eos_token_id)\n","\n","    # Decode the generated output and display the chatbot's response\n","    response = tokenizer.decode(output[0], skip_special_tokens=True)\n","    print(\"Chatbot:\", response)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":939},"executionInfo":{"elapsed":18833,"status":"ok","timestamp":1690182628037,"user":{"displayName":"HummingBird's Tech","userId":"15801504552720898939"},"user_tz":-330},"id":"aXsU6E7wqvCc","outputId":"c5758b45-471e-4398-8ab0-9735c524fec4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting googletrans==4.0.0-rc1\n","  Downloading googletrans-4.0.0rc1.tar.gz (20 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting httpx==0.13.3 (from googletrans==4.0.0-rc1)\n","  Downloading httpx-0.13.3-py3-none-any.whl (55 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.1/55.1 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2023.5.7)\n","Collecting hstspreload (from httpx==0.13.3->googletrans==4.0.0-rc1)\n","  Downloading hstspreload-2023.1.1-py3-none-any.whl (1.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.3.0)\n","Collecting chardet==3.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n","  Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting idna==2.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n","  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting rfc3986<2,>=1.3 (from httpx==0.13.3->googletrans==4.0.0-rc1)\n","  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n","Collecting httpcore==0.9.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n","  Downloading httpcore-0.9.1-py3-none-any.whl (42 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting h11<0.10,>=0.8 (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n","  Downloading h11-0.9.0-py2.py3-none-any.whl (53 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting h2==3.* (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n","  Downloading h2-3.2.0-py2.py3-none-any.whl (65 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.0/65.0 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting hyperframe<6,>=5.2.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n","  Downloading hyperframe-5.2.0-py2.py3-none-any.whl (12 kB)\n","Collecting hpack<4,>=3.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n","  Downloading hpack-3.0.0-py2.py3-none-any.whl (38 kB)\n","Building wheels for collected packages: googletrans\n","  Building wheel for googletrans (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for googletrans: filename=googletrans-4.0.0rc1-py3-none-any.whl size=17397 sha256=ab2b21d69a3adcca02c73357f68ae40930359c8f52e9a2ea0668be11567c2db4\n","  Stored in directory: /root/.cache/pip/wheels/c0/59/9f/7372f0cf70160fe61b528532e1a7c8498c4becd6bcffb022de\n","Successfully built googletrans\n","Installing collected packages: rfc3986, hyperframe, hpack, h11, chardet, idna, hstspreload, h2, httpcore, httpx, googletrans\n","  Attempting uninstall: chardet\n","    Found existing installation: chardet 4.0.0\n","    Uninstalling chardet-4.0.0:\n","      Successfully uninstalled chardet-4.0.0\n","  Attempting uninstall: idna\n","    Found existing installation: idna 3.4\n","    Uninstalling idna-3.4:\n","      Successfully uninstalled idna-3.4\n","Successfully installed chardet-3.0.4 googletrans-4.0.0rc1 h11-0.9.0 h2-3.2.0 hpack-3.0.0 hstspreload-2023.1.1 httpcore-0.9.1 httpx-0.13.3 hyperframe-5.2.0 idna-2.10 rfc3986-1.5.0\n"]},{"data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["chardet","idna"]}}},"metadata":{},"output_type":"display_data"}],"source":["!pip install googletrans==4.0.0-rc1\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15547,"status":"ok","timestamp":1690182734835,"user":{"displayName":"HummingBird's Tech","userId":"15801504552720898939"},"user_tz":-330},"id":"DOENm-dAu-Gq","outputId":"d6fe916c-92ab-4450-fcd3-a0d6ecb344a3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Simple Text Translator\n","----------------------\n","Enter the text to translate: I Am Very Happy Today\n","Enter the target language (e.g., 'fr' for French, 'es' for Spanish): Arabic\n","\n","Translated Text: أنا سعيد جدا اليوم\n"]}],"source":["from googletrans import Translator\n","\n","def translate_text(text, target_language):\n","    translator = Translator()\n","    translated_text = translator.translate(text, dest=target_language)\n","\n","    return translated_text.text\n","\n","if __name__ == \"__main__\":\n","    print(\"Simple Text Translator\")\n","    print(\"----------------------\")\n","    input_text = input(\"Enter the text to translate: \")\n","    target_language = input(\"Enter the target language (e.g., 'fr' for French, 'es' for Spanish): \")\n","\n","    translated_text = translate_text(input_text, target_language)\n","    print(f\"\\nTranslated Text: {translated_text}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10520,"status":"ok","timestamp":1690182824177,"user":{"displayName":"HummingBird's Tech","userId":"15801504552720898939"},"user_tz":-330},"id":"rgQWb9D-vDlc","outputId":"eaf9e88a-4ebe-4044-8875-af917a953dd3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.31.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.16.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.5.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.10)\n"]}],"source":["!pip install transformers\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":130250,"status":"ok","timestamp":1690183091953,"user":{"displayName":"HummingBird's Tech","userId":"15801504552720898939"},"user_tz":-330},"id":"bnAZH9CmvzXW","outputId":"59300f19-c3f7-4df9-ab0a-c4e7b03b307e"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package gutenberg to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/gutenberg.zip.\n","<ipython-input-1-7e19da8efa79>:34: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  X = np.zeros((len(input_sequences), seq_length, len(chars)), dtype=np.bool)\n","<ipython-input-1-7e19da8efa79>:35: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  y = np.zeros((len(input_sequences), len(chars)), dtype=np.bool)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/30\n","244/244 [==============================] - 15s 12ms/step - loss: 2.8131\n","Epoch 2/30\n","244/244 [==============================] - 2s 8ms/step - loss: 2.4529\n","Epoch 3/30\n","244/244 [==============================] - 2s 8ms/step - loss: 2.2947\n","Epoch 4/30\n","244/244 [==============================] - 2s 8ms/step - loss: 2.2103\n","Epoch 5/30\n","244/244 [==============================] - 2s 8ms/step - loss: 2.1428\n","Epoch 6/30\n","244/244 [==============================] - 2s 8ms/step - loss: 2.0850\n","Epoch 7/30\n","244/244 [==============================] - 2s 8ms/step - loss: 2.0355\n","Epoch 8/30\n","244/244 [==============================] - 2s 8ms/step - loss: 1.9948\n","Epoch 9/30\n","244/244 [==============================] - 2s 8ms/step - loss: 1.9545\n","Epoch 10/30\n","244/244 [==============================] - 2s 8ms/step - loss: 1.9206\n","Epoch 11/30\n","244/244 [==============================] - 2s 8ms/step - loss: 1.8908\n","Epoch 12/30\n","244/244 [==============================] - 2s 9ms/step - loss: 1.8607\n","Epoch 13/30\n","244/244 [==============================] - 2s 8ms/step - loss: 1.8331\n","Epoch 14/30\n","244/244 [==============================] - 2s 8ms/step - loss: 1.8084\n","Epoch 15/30\n","244/244 [==============================] - 2s 8ms/step - loss: 1.7842\n","Epoch 16/30\n","244/244 [==============================] - 2s 8ms/step - loss: 1.7591\n","Epoch 17/30\n","244/244 [==============================] - 2s 8ms/step - loss: 1.7364\n","Epoch 18/30\n","244/244 [==============================] - 2s 9ms/step - loss: 1.7123\n","Epoch 19/30\n","244/244 [==============================] - 2s 8ms/step - loss: 1.6897\n","Epoch 20/30\n","244/244 [==============================] - 2s 8ms/step - loss: 1.6651\n","Epoch 21/30\n","244/244 [==============================] - 2s 8ms/step - loss: 1.6434\n","Epoch 22/30\n","244/244 [==============================] - 2s 8ms/step - loss: 1.6206\n","Epoch 23/30\n","244/244 [==============================] - 2s 8ms/step - loss: 1.5958\n","Epoch 24/30\n","244/244 [==============================] - 2s 8ms/step - loss: 1.5722\n","Epoch 25/30\n","244/244 [==============================] - 2s 8ms/step - loss: 1.5484\n","Epoch 26/30\n","244/244 [==============================] - 2s 8ms/step - loss: 1.5239\n","Epoch 27/30\n","244/244 [==============================] - 2s 8ms/step - loss: 1.5006\n","Epoch 28/30\n","244/244 [==============================] - 2s 8ms/step - loss: 1.4748\n","Epoch 29/30\n","244/244 [==============================] - 2s 8ms/step - loss: 1.4482\n","Epoch 30/30\n","244/244 [==============================] - 2s 8ms/step - loss: 1.4244\n","to be or not to beeoeeoeomsomommemmememmaeaammmmmommsmsoeoomeosmosoeeosommmssmmmaesmoaoommmsmmesososooooeeeeoomseeooeooooeemssomsammmaoeommommoeomeommsmmommmoooeesoememmeeaommeemsmmommmmmomommomseoooeeeeoommseeeaomommmoemammmsossmmmommomomommoseoeeoooeoooeeosoomoaeemeooeeomsmemsommmaaoemseosoosomooeoosemomoomeomosmmmmooeoemooeommeeoeomseasaommmoomamomemsmmsosmmsmoooeoeemmeemomommoooeeeeoommmooomoomeoeeeeeeeeomomsosmmmmmoooeeomoeoeeeeeeooeooesosoosmmmmmmmoomeeoeoomomessmssmoommmmmsemommmmmmmmmmmmmmmoeomeoeoeoeoemm\n"]}],"source":["import numpy as np\n","import random\n","import string\n","import nltk\n","from nltk.corpus import gutenberg\n","from keras.models import Sequential\n","from keras.layers import LSTM, Dense\n","\n","# Download the Shakespeare corpus from nltk\n","nltk.download('gutenberg')\n","\n","# Get the text of Shakespeare's works from the Gutenberg corpus\n","shakespeare_text = gutenberg.raw('shakespeare-hamlet.txt')\n","\n","# Preprocess the text by removing punctuation and converting to lowercase\n","translator = str.maketrans('', '', string.punctuation)\n","shakespeare_text = shakespeare_text.translate(translator).lower()\n","\n","# Create character-to-index and index-to-character mappings\n","chars = sorted(list(set(shakespeare_text)))\n","char_to_idx = {char: idx for idx, char in enumerate(chars)}\n","idx_to_char = {idx: char for idx, char in enumerate(chars)}\n","\n","# Create sequences of characters as input and target for training\n","seq_length = 100  # Number of characters in each sequence\n","step = 5  # Step size to create overlapping sequences\n","input_sequences = []\n","target_sequences = []\n","for i in range(0, len(shakespeare_text) - seq_length, step):\n","    input_sequences.append(shakespeare_text[i:i+seq_length])\n","    target_sequences.append(shakespeare_text[i+seq_length])\n","\n","# Convert input sequences to numerical representations using char_to_idx mapping\n","X = np.zeros((len(input_sequences), seq_length, len(chars)), dtype=np.bool)\n","y = np.zeros((len(input_sequences), len(chars)), dtype=np.bool)\n","for i, sequence in enumerate(input_sequences):\n","    for t, char in enumerate(sequence):\n","        X[i, t, char_to_idx[char]] = 1\n","    y[i, char_to_idx[target_sequences[i]]] = 1\n","\n","# Build the LSTM model\n","model = Sequential()\n","model.add(LSTM(128, input_shape=(seq_length, len(chars))))\n","model.add(Dense(len(chars), activation='softmax'))\n","\n","model.compile(loss='categorical_crossentropy', optimizer='adam')\n","\n","# Train the LSTM model\n","model.fit(X, y, epochs=30, batch_size=128)\n","\n","# Function to generate text using the trained LSTM model\n","def generate_text(seed_text, length=200):\n","    generated_text = seed_text\n","    for _ in range(length):\n","        x_pred = np.zeros((1, seq_length, len(chars)))\n","        for t, char in enumerate(seed_text):\n","            x_pred[0, t, char_to_idx[char]] = 1\n","\n","        predicted_idx = np.argmax(model.predict(x_pred, verbose=0))\n","        predicted_char = idx_to_char[predicted_idx]\n","\n","        generated_text += predicted_char\n","        seed_text = seed_text[1:] + predicted_char\n","\n","    return generated_text\n","\n","# Generate text with a seed\n","seed_text = \"to be or not to be\"\n","generated_text = generate_text(seed_text, length=500)\n","print(generated_text)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xdti5JhXwLlI"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"191drpdQRI_KtXnlIalVHsQM-VXvGpS9V","timestamp":1707988965888}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0fcaacc473854d5ca4ba8eb3dc5d8592":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1124a1dc20644467bfb89d6c1e16db2a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"12bc38728de44a07965f879779530323":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_63c4eb22837e4fe0a5d09a6e86b504fb","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4cfe845d4629457fb5538abafe8683b5","value":456318}},"153069c35ca440be940f49e9c5c65294":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_15bfdced7d0141759287b9790726a04c","placeholder":"​","style":"IPY_MODEL_b5c3dedf6ce948a3a26b7e43769a9bab","value":"Downloading (…)neration_config.json: 100%"}},"15bfdced7d0141759287b9790726a04c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"25e4bf1c328641f0b66040244f0d2947":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_97da7963163d4fc09631af23f9c1fc1e","placeholder":"​","style":"IPY_MODEL_a15fecf2e695430d8fbe6bc5e07d27ac","value":" 548M/548M [00:10&lt;00:00, 72.9MB/s]"}},"328c5b9f1c364ef8810b733158e39536":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7ac4cc69727243b3933d22558a8cb551","placeholder":"​","style":"IPY_MODEL_0fcaacc473854d5ca4ba8eb3dc5d8592","value":"Downloading model.safetensors: 100%"}},"36ef3fa1e69d47eb8fbdc0d9b285dd26":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9b09e2e4ff7843fdba3957fb1c41af2d","max":124,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fb0667832da543cd8880c905b0636476","value":124}},"3a7c000be3414b4f82c00db306f60db1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3e39c30ecb4f42fa9b547206ae461064":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b154f814faca40de8da2ae42f0cbcc0c","placeholder":"​","style":"IPY_MODEL_767ef0d4632641a899a29f60089edfea","value":"Downloading (…)lve/main/config.json: 100%"}},"4c4d40f3c5e248d1b211eecedcd872ed":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1124a1dc20644467bfb89d6c1e16db2a","placeholder":"​","style":"IPY_MODEL_5b1fd71a126140bca9bfb6cadff694f3","value":" 1.04M/1.04M [00:00&lt;00:00, 3.28MB/s]"}},"4cfe845d4629457fb5538abafe8683b5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"50c04146cd564b8d87b7adb5a8b6c5b5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c79e4bcae0a84ccbad2e93fe68a6d065","placeholder":"​","style":"IPY_MODEL_86e4a4ff2ed24c1ebd55a96426803374","value":"Downloading (…)olve/main/vocab.json: 100%"}},"5601fa2bf7b94502ae0c41e3e9608b4f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_636e3ddb13f245f3b50fe779285e3b60","placeholder":"​","style":"IPY_MODEL_beb36773ab6045ceacb291d3aa624037","value":" 456k/456k [00:00&lt;00:00, 1.44MB/s]"}},"57900d8c7e92422bbbdbfade9aa2e956":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ef313157c8dd4dc7b34b9da8aebb4ead","placeholder":"​","style":"IPY_MODEL_f3f0be219dc84ebda8f3b581bad481f8","value":"Downloading (…)olve/main/merges.txt: 100%"}},"5a038e1c4ec54db0aaaf3e52a98c3aeb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_50c04146cd564b8d87b7adb5a8b6c5b5","IPY_MODEL_7f7d2645fc51437091f1973ffcb8ea73","IPY_MODEL_4c4d40f3c5e248d1b211eecedcd872ed"],"layout":"IPY_MODEL_fedd8f4e19c5497b83e82d9168085bac"}},"5a300bc8e74d4b61b06aabcacfffbef3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b8c96f049a564da281fb6db766d2b83f","placeholder":"​","style":"IPY_MODEL_8cd82deacc9f482cb5b14af93d544428","value":" 665/665 [00:00&lt;00:00, 9.26kB/s]"}},"5a8e01b3610844faa200f1255a1fdaa5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5b1fd71a126140bca9bfb6cadff694f3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5c737cc0b2fa49f3bb6c740237285198":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"636e3ddb13f245f3b50fe779285e3b60":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"63c4eb22837e4fe0a5d09a6e86b504fb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6804a5b303134aa5a942ae628c0633b0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bd7eda5aa11640b79e0190b156365475","max":548105171,"min":0,"orientation":"horizontal","style":"IPY_MODEL_da6eabf6d014466a9896881362783f4b","value":548105171}},"69ca8c5551f14496beb0cd8d7cd0479e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f2a9aaf4d6e9413b944f9163b609932c","placeholder":"​","style":"IPY_MODEL_ac4487649d83456cbcaf805c41248631","value":" 124/124 [00:00&lt;00:00, 1.67kB/s]"}},"767ef0d4632641a899a29f60089edfea":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"76d468216f9c41ad8b4f0416573236dc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_57900d8c7e92422bbbdbfade9aa2e956","IPY_MODEL_12bc38728de44a07965f879779530323","IPY_MODEL_5601fa2bf7b94502ae0c41e3e9608b4f"],"layout":"IPY_MODEL_3a7c000be3414b4f82c00db306f60db1"}},"7ac4cc69727243b3933d22558a8cb551":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7c8132ed06834bb2a8bb228c153042b7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7f7d2645fc51437091f1973ffcb8ea73":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5c737cc0b2fa49f3bb6c740237285198","max":1042301,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7c8132ed06834bb2a8bb228c153042b7","value":1042301}},"86e4a4ff2ed24c1ebd55a96426803374":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8cd82deacc9f482cb5b14af93d544428":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"97da7963163d4fc09631af23f9c1fc1e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9b09e2e4ff7843fdba3957fb1c41af2d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9baa1971c83344c99d7b0c77149c2aad":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3e39c30ecb4f42fa9b547206ae461064","IPY_MODEL_e733318cefa141d69255cf395516062c","IPY_MODEL_5a300bc8e74d4b61b06aabcacfffbef3"],"layout":"IPY_MODEL_e637701765d449c4a0f5d1dd39767e16"}},"9f5e4df6608f4df08e8784cd47dfe77e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a15fecf2e695430d8fbe6bc5e07d27ac":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ac4487649d83456cbcaf805c41248631":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b154f814faca40de8da2ae42f0cbcc0c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b30a028edb674ca09875b0eba3578dc6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b5c3dedf6ce948a3a26b7e43769a9bab":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b5d95b3652b24d93a4cc597e45cc9384":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_153069c35ca440be940f49e9c5c65294","IPY_MODEL_36ef3fa1e69d47eb8fbdc0d9b285dd26","IPY_MODEL_69ca8c5551f14496beb0cd8d7cd0479e"],"layout":"IPY_MODEL_9f5e4df6608f4df08e8784cd47dfe77e"}},"b8c96f049a564da281fb6db766d2b83f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bd7eda5aa11640b79e0190b156365475":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"beb36773ab6045ceacb291d3aa624037":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c322522ace7346c2b5eeed492582d411":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c79e4bcae0a84ccbad2e93fe68a6d065":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"da6eabf6d014466a9896881362783f4b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e637701765d449c4a0f5d1dd39767e16":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e733318cefa141d69255cf395516062c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5a8e01b3610844faa200f1255a1fdaa5","max":665,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b30a028edb674ca09875b0eba3578dc6","value":665}},"ef313157c8dd4dc7b34b9da8aebb4ead":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f26e711a4bce4860bc152298ed7f9e42":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_328c5b9f1c364ef8810b733158e39536","IPY_MODEL_6804a5b303134aa5a942ae628c0633b0","IPY_MODEL_25e4bf1c328641f0b66040244f0d2947"],"layout":"IPY_MODEL_c322522ace7346c2b5eeed492582d411"}},"f2a9aaf4d6e9413b944f9163b609932c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f3f0be219dc84ebda8f3b581bad481f8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fb0667832da543cd8880c905b0636476":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fedd8f4e19c5497b83e82d9168085bac":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}
